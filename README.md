# AI Text Detection API

A Flask-based REST API for detecting AI-generated text using a fine-tuned RoBERTa model.

## ğŸ¯ Model Performance

- **Accuracy**: 98.69%
- **Precision**: 97.76%
- **Recall**: 99.66%
- **F1 Score**: 98.70%
- **Parameters**: 124,647,170 (~125M)
- **Model Size**: 475.51 MB

## ğŸš€ Features

- Fine-tuned RoBERTa-base model for AI text detection
- REST API with multiple endpoints
- Real-time text classification
- Confidence scores for predictions
- Minimum word count validation

## ğŸ“‹ Requirements

- Python 3.11+
- PyTorch
- Transformers
- Flask
- See `requirements.txt` for complete list

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone <your-repo-url>
cd <repo-name>
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Ensure the model files are present in `ensemble_models/roberta-base/`

## ğŸƒ Running Locally

```bash
python app.py
```

The API will start on `http://localhost:10000`

## ğŸ“¡ API Endpoints

### 1. Home - `GET /`
Get API information and usage instructions.

### 2. Health Check - `GET /health`
Check if the API and model are loaded.

### 3. Model Info - `GET /model-info`
Get detailed model information and metrics.

### 4. Predict - `POST /predict`
Detect if text is AI-generated or human-written.

**Request Body:**
```json
{
  "text": "Your text to analyze (minimum 50 words)",
  "min_words": 50
}
```

**Response:**
```json
{
  "success": true,
  "prediction": "AI-GENERATED",
  "prediction_label": 1,
  "word_count": 75,
  "text_length": 450,
  "ai_confidence": "99.75%",
  "human_confidence": "0.25%"
}
```

## ğŸ§ª Testing

Run the test script to verify model loading:
```bash
python test_model_load.py
```

## ğŸŒ Deployment to Render

This project is configured for easy deployment to Render.

1. Push your code to GitHub
2. Connect your GitHub repository to Render
3. Render will automatically detect `render.yaml` and deploy

**Important**: The model files (~476 MB) must be included in your repository.

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                          # Main Flask application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ Procfile                        # Render deployment config
â”œâ”€â”€ render.yaml                     # Render service configuration
â”œâ”€â”€ ensemble_models/
â”‚   â””â”€â”€ roberta-base/              # Fine-tuned model files
â”‚       â”œâ”€â”€ model.safetensors      # Model weights (475 MB)
â”‚       â”œâ”€â”€ config.json            # Model configuration
â”‚       â”œâ”€â”€ tokenizer.json         # Tokenizer
â”‚       â””â”€â”€ ...                    # Other model files
â””â”€â”€ README.md                       # This file
```

## ğŸ”§ Configuration

- **Port**: Default 10000 (configurable via `PORT` environment variable)
- **Device**: Automatically uses CUDA if available, otherwise CPU
- **Min Words**: Default 50 words for text analysis

## ğŸ“ License

[Add your license here]

## ğŸ‘¥ Authors

[Add your name/team here]

## ğŸ™ Acknowledgments

- Model: RoBERTa-base (fine-tuned)
- Framework: Hugging Face Transformers
- Training samples: 40,000
